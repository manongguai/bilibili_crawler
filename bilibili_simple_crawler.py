#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Bç«™è§†é¢‘çˆ¬è™«ç¨‹åºï¼ˆç®€åŒ–ç‰ˆï¼‰
ä½¿ç”¨requestsç›´æ¥çˆ¬å–Bç«™APIï¼Œä¸ä¾èµ–bilibili-apiåº“

ä½œè€…ï¼šKirk
æ—¥æœŸï¼š2025-12-08
"""

import json
import os
import sys
import time
import random
import requests
from datetime import datetime
from typing import Dict, List, Optional
import warnings

# ç¦ç”¨SSLè­¦å‘Š
warnings.filterwarnings('ignore', message='Unverified HTTPS request')
try:
    import urllib3
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
except ImportError:
    pass


class BilibiliSimpleCrawler:
    """Bç«™è§†é¢‘çˆ¬è™«ç±»ï¼ˆç®€åŒ–ç‰ˆï¼‰"""

    def __init__(self):
        """åˆå§‹åŒ–çˆ¬è™«é…ç½®"""
        self.max_retries = 8  # æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆè¿›ä¸€æ­¥å¢åŠ ï¼‰
        self.retry_delay = 10  # é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼Œè¿›ä¸€æ­¥å¢åŠ ï¼‰
        self.request_delay = 5  # åŸºç¡€è¯·æ±‚é—´éš”ï¼ˆç§’ï¼Œè¿›ä¸€æ­¥å¢åŠ ï¼‰
        self.videos_per_page = 10  # æ¯é¡µè§†é¢‘æ•°é‡ï¼ˆè¿›ä¸€æ­¥å‡å°‘ï¼‰
        self.output_dir = "./output"  # è¾“å‡ºç›®å½•

        # å¤šä¸ªUser-Agentè½®æ¢
        self.user_agents = [
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/119.0',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        ]

        # è·å–éšæœºUser-Agent
        import random
        user_agent = random.choice(self.user_agents)

        self.headers = {
            'User-Agent': user_agent,
            'Referer': 'https://www.bilibili.com/',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache',
            'sec-ch-ua': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
            'sec-ch-ua-mobile': '?0',
            'sec-ch-ua-platform': '"macOS"',
            'Sec-Fetch-Dest': 'empty',
            'Sec-Fetch-Mode': 'cors',
            'Sec-Fetch-Site': 'same-site',
            'Origin': 'https://www.bilibili.com'
        }

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(self.output_dir, exist_ok=True)

    def get_user_info(self, uid: int) -> Optional[Dict]:
        """
        è·å–ç”¨æˆ·ä¿¡æ¯

        Args:
            uid: ç”¨æˆ·UID

        Returns:
            ç”¨æˆ·ä¿¡æ¯å­—å…¸ï¼Œå¤±è´¥è¿”å›None
        """
        url = f"https://api.bilibili.com/x/space/arc/search"
        params = {
            'mid': uid,
            'ps': 1,
            'pn': 1
        }

        for attempt in range(self.max_retries):
            try:
                # æ·»åŠ éšæœºå»¶è¿Ÿå’ŒUser-Agentè½®æ¢
                if attempt > 0:
                    # é¢‘ç‡é™åˆ¶æ—¶ä½¿ç”¨æ›´é•¿çš„å»¶è¿Ÿ
                    if attempt > 2:
                        delay = 30 + random.uniform(10, 20)  # 30-50ç§’
                        print(f"ğŸ”„ æ£€æµ‹åˆ°å¤šæ¬¡å¤±è´¥ï¼Œç­‰å¾… {delay:.1f} ç§’...")
                    else:
                        delay = self.retry_delay + random.uniform(5, 10)  # 15-20ç§’
                        print(f"ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                    time.sleep(delay)

                    # è½®æ¢User-Agent
                    user_agent = random.choice(self.user_agents)
                    self.headers['User-Agent'] = user_agent

                response = requests.get(
                    url,
                    params=params,
                    headers=self.headers,
                    timeout=15,
                    verify=False  # ç¦ç”¨SSLéªŒè¯ï¼ˆä»…ç”¨äºè§£å†³å…¼å®¹æ€§é—®é¢˜ï¼‰
                )
                response.raise_for_status()
                data = response.json()

                if data.get('code') == 0:
                    return data.get('data', {}).get('list', {}).get('vlist', [])
                else:
                    error_msg = data.get('message', 'æœªçŸ¥é”™è¯¯')
                    if 'é¢‘ç¹' in error_msg or 'é¢‘ç‡' in error_msg:
                        print(f"è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œç­‰å¾…æ›´é•¿æ—¶é—´...")
                        time.sleep(30)  # é¢‘ç‡é™åˆ¶æ—¶ç­‰å¾…æ›´é•¿æ—¶é—´
                        continue
                    print(f"è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥ï¼š{error_msg}")
                    return None

            except requests.exceptions.Timeout:
                print(f"è¯·æ±‚è¶…æ—¶ï¼ˆå°è¯• {attempt + 1}/{self.max_retries}ï¼‰")
            except requests.exceptions.ConnectionError:
                print(f"ç½‘ç»œè¿æ¥é”™è¯¯ï¼ˆå°è¯• {attempt + 1}/{self.max_retries}ï¼‰")
            except Exception as e:
                print(f"è·å–ç”¨æˆ·ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯ï¼ˆå°è¯• {attempt + 1}/{self.max_retries}ï¼‰ï¼š{e}")

            if attempt < self.max_retries - 1:
                time.sleep(self.retry_delay)
            else:
                print("å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                return None

    def get_user_videos(self, uid: int, page: int = 1) -> Optional[Dict]:
        """
        è·å–ç”¨æˆ·è§†é¢‘åˆ—è¡¨ï¼ˆåˆ†é¡µï¼‰

        Args:
            uid: ç”¨æˆ·UID
            page: é¡µç ï¼Œä»1å¼€å§‹

        Returns:
            è§†é¢‘åˆ—è¡¨æ•°æ®ï¼Œå¤±è´¥è¿”å›None
        """
        url = "https://api.bilibili.com/x/space/arc/search"
        params = {
            'mid': uid,
            'ps': self.videos_per_page,
            'pn': page,
            'order': 'pubdate'  # æŒ‰å‘å¸ƒæ—¶é—´æ’åº
        }

        for attempt in range(self.max_retries):
            try:
                # æ·»åŠ éšæœºå»¶è¿Ÿå’ŒUser-Agentè½®æ¢
                if attempt > 0:
                    # é¢‘ç‡é™åˆ¶æ—¶ä½¿ç”¨æ›´é•¿çš„å»¶è¿Ÿ
                    if attempt > 2:
                        delay = 30 + random.uniform(10, 20)  # 30-50ç§’
                        print(f"ğŸ”„ æ£€æµ‹åˆ°å¤šæ¬¡å¤±è´¥ï¼Œç­‰å¾… {delay:.1f} ç§’...")
                    else:
                        delay = self.retry_delay + random.uniform(5, 10)  # 15-20ç§’
                        print(f"ç­‰å¾… {delay:.1f} ç§’åé‡è¯•ç¬¬ {page} é¡µ...")
                    time.sleep(delay)

                    # è½®æ¢User-Agent
                    user_agent = random.choice(self.user_agents)
                    self.headers['User-Agent'] = user_agent

                response = requests.get(
                    url,
                    params=params,
                    headers=self.headers,
                    timeout=20,
                    verify=False  # ç¦ç”¨SSLéªŒè¯ï¼ˆä»…ç”¨äºè§£å†³å…¼å®¹æ€§é—®é¢˜ï¼‰
                )
                response.raise_for_status()
                data = response.json()

                if data.get('code') == 0:
                    return data.get('data', {})
                else:
                    error_msg = data.get('message', 'æœªçŸ¥é”™è¯¯')
                    if 'é¢‘ç¹' in error_msg or 'é¢‘ç‡' in error_msg:
                        print(f"è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œç­‰å¾…æ›´é•¿æ—¶é—´ï¼ˆ{page}é¡µï¼‰...")
                        time.sleep(30)  # é¢‘ç‡é™åˆ¶æ—¶ç­‰å¾…æ›´é•¿æ—¶é—´
                        continue
                    elif 'ä¸å­˜åœ¨' in error_msg or 'æ‰¾ä¸åˆ°' in error_msg:
                        print(f"ç”¨æˆ·ä¸å­˜åœ¨æˆ–æ²¡æœ‰å…¬å¼€è§†é¢‘ï¼ˆ{page}é¡µï¼‰")
                        return None
                    else:
                        print(f"è·å–è§†é¢‘åˆ—è¡¨å¤±è´¥ï¼ˆé¡µç ï¼š{page}ï¼‰ï¼š{error_msg}")
                        return None

            except requests.exceptions.Timeout:
                print(f"è¯·æ±‚è¶…æ—¶ï¼ˆé¡µç ï¼š{page}ï¼Œå°è¯• {attempt + 1}/{self.max_retries}ï¼‰")
            except requests.exceptions.ConnectionError:
                print(f"ç½‘ç»œè¿æ¥é”™è¯¯ï¼ˆé¡µç ï¼š{page}ï¼Œå°è¯• {attempt + 1}/{self.max_retries}ï¼‰")
            except Exception as e:
                print(f"è·å–è§†é¢‘åˆ—è¡¨æ—¶å‘ç”Ÿé”™è¯¯ï¼ˆé¡µç ï¼š{page}ï¼Œå°è¯• {attempt + 1}/{self.max_retries}ï¼‰ï¼š{e}")

            if attempt < self.max_retries - 1:
                time.sleep(self.retry_delay)
            else:
                print(f"ç¬¬ {page} é¡µå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                return None

    def fetch_all_videos_with_incremental_save(self, uid: int) -> int:
        """
        è·å–ç”¨æˆ·çš„æ‰€æœ‰è§†é¢‘å¹¶å¢é‡ä¿å­˜

        Args:
            uid: ç”¨æˆ·UID

        Returns:
            è·å–åˆ°çš„è§†é¢‘æ€»æ•°
        """
        # åˆå§‹åŒ–ä¿å­˜æ–‡ä»¶
        save_filepath = self.init_save_file(uid)
        if not save_filepath:
            return 0

        total_videos = 0
        page = 1

        print("å¼€å§‹çˆ¬å–è§†é¢‘åˆ—è¡¨...")

        while True:
            # æ·»åŠ æ™ºèƒ½è¯·æ±‚å»¶è¿Ÿ
            if page > 1:
                # åŸºç¡€å»¶è¿Ÿ + éšæœºå»¶è¿Ÿ
                base_delay = self.request_delay + (page - 1) * 0.5  # é€é¡µå¢åŠ å»¶è¿Ÿ
                random_delay = random.uniform(2, 5)
                total_delay = base_delay + random_delay
                print(f"ç­‰å¾… {total_delay:.1f} ç§’åè·å–ä¸‹ä¸€é¡µ...")
                time.sleep(total_delay)

            # è·å–å½“å‰é¡µè§†é¢‘
            print(f"æ­£åœ¨è·å–ç¬¬ {page} é¡µ...")
            data = self.get_user_videos(uid, page)

            if not data:
                print(f"ç¬¬ {page} é¡µè·å–å¤±è´¥ï¼Œåœæ­¢çˆ¬å–")
                break

            # æå–è§†é¢‘åˆ—è¡¨
            videos = data.get('list', {}).get('vlist', [])

            if not videos:
                print(f"ç¬¬ {page} é¡µæ²¡æœ‰è§†é¢‘ï¼Œçˆ¬å–å®Œæˆ")
                break

            # å¤„ç†æ¯ä¸ªè§†é¢‘ä¿¡æ¯
            page_videos = []
            for video_info in videos:
                video_data = {
                    'aid': video_info.get('aid'),
                    'bvid': video_info.get('bvid'),
                    'title': video_info.get('title'),
                    'url': f"https://www.bilibili.com/video/{video_info.get('bvid')}",
                    'duration': video_info.get('length'),
                    'created': video_info.get('created'),
                    'view': video_info.get('play'),
                    'danmaku': video_info.get('video_review'),
                    'reply': video_info.get('comment'),
                    'pic': video_info.get('pic'),
                    'description': video_info.get('description', '')
                }
                page_videos.append(video_data)

            # ç«‹å³ä¿å­˜åˆ°æ–‡ä»¶
            if self.append_videos_to_file(save_filepath, page_videos):
                total_videos += len(page_videos)
                print(f"âœ… ç¬¬ {page} é¡µå®Œæˆï¼š{len(page_videos)} ä¸ªè§†é¢‘ï¼Œæ€»è®¡ {total_videos} ä¸ª")
            else:
                print(f"âŒ ç¬¬ {page} é¡µä¿å­˜å¤±è´¥")
                break

            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šé¡µé¢
            page_info = data.get('page', {})
            count = page_info.get('count', 0)
            if count > 0 and total_videos >= count:
                print(f"âœ… å·²è·å–æ‰€æœ‰ {count} ä¸ªè§†é¢‘")
                break

            # å¦‚æœå½“å‰é¡µçš„è§†é¢‘æ•°å°‘äºæœŸæœ›ï¼Œè¯´æ˜æ²¡æœ‰æ›´å¤šé¡µé¢äº†
            if len(videos) < self.videos_per_page:
                print(f"âœ… å½“å‰é¡µè§†é¢‘æ•°ä¸è¶³ï¼Œè¯´æ˜å·²åˆ°æœ€åä¸€é¡µ")
                break

            page += 1

        # å®Œæˆä¿å­˜
        self.finalize_save_file(save_filepath)

        return total_videos

    def fetch_all_videos(self, uid: int) -> List[Dict]:
        """
        è·å–ç”¨æˆ·çš„æ‰€æœ‰è§†é¢‘ï¼ˆåŸç‰ˆæœ¬ï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰

        Args:
            uid: ç”¨æˆ·UID

        Returns:
            æ‰€æœ‰è§†é¢‘çš„åˆ—è¡¨
        """
        all_videos = []
        page = 1

        print("å¼€å§‹çˆ¬å–è§†é¢‘åˆ—è¡¨...")

        while True:
            # æ·»åŠ æ™ºèƒ½è¯·æ±‚å»¶è¿Ÿ
            if page > 1:
                # åŸºç¡€å»¶è¿Ÿ + éšæœºå»¶è¿Ÿ
                base_delay = self.request_delay + (page - 1) * 0.5  # é€é¡µå¢åŠ å»¶è¿Ÿ
                random_delay = random.uniform(2, 5)
                total_delay = base_delay + random_delay
                print(f"ç­‰å¾… {total_delay:.1f} ç§’åè·å–ä¸‹ä¸€é¡µ...")
                time.sleep(total_delay)

            # è·å–å½“å‰é¡µè§†é¢‘
            print(f"æ­£åœ¨è·å–ç¬¬ {page} é¡µ...")
            data = self.get_user_videos(uid, page)

            if not data:
                break

            # æå–è§†é¢‘åˆ—è¡¨
            videos = data.get('list', {}).get('vlist', [])

            if not videos:
                print(f"ç¬¬ {page} é¡µæ²¡æœ‰è§†é¢‘ï¼Œçˆ¬å–å®Œæˆ")
                break

            # å¤„ç†æ¯ä¸ªè§†é¢‘ä¿¡æ¯
            for video_info in videos:
                video_data = {
                    'aid': video_info.get('aid'),
                    'bvid': video_info.get('bvid'),
                    'title': video_info.get('title'),
                    'url': f"https://www.bilibili.com/video/{video_info.get('bvid')}",
                    'duration': video_info.get('length'),
                    'created': video_info.get('created'),
                    'view': video_info.get('play'),
                    'danmaku': video_info.get('video_review'),
                    'reply': video_info.get('comment'),
                    'pic': video_info.get('pic'),
                    'description': video_info.get('description', '')
                }
                all_videos.append(video_data)

            print(f"å·²è·å–ç¬¬ {page} é¡µï¼Œæœ¬é¡µ {len(videos)} ä¸ªè§†é¢‘ï¼Œæ€»è®¡ {len(all_videos)} ä¸ªè§†é¢‘")

            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šé¡µé¢
            page_info = data.get('page', {})
            count = page_info.get('count', 0)
            if count > 0 and len(all_videos) >= count:
                print(f"å·²è·å–æ‰€æœ‰ {count} ä¸ªè§†é¢‘")
                break

            # å¦‚æœå½“å‰é¡µçš„è§†é¢‘æ•°å°‘äºæœŸæœ›ï¼Œè¯´æ˜æ²¡æœ‰æ›´å¤šé¡µé¢äº†
            if len(videos) < self.videos_per_page:
                break

            page += 1

        return all_videos

    def init_save_file(self, uid: int) -> str:
        """
        åˆå§‹åŒ–ä¿å­˜æ–‡ä»¶

        Args:
            uid: ç”¨æˆ·UID

        Returns:
            æ–‡ä»¶è·¯å¾„
        """
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        filename = f"videos_{uid}_{timestamp}.json"
        filepath = os.path.join(self.output_dir, filename)

        # åˆå§‹åŒ–æ–‡ä»¶ç»“æ„
        init_data = {
            "user_info": {
                "uid": uid,
                "total_videos": 0,
                "start_time": current_time,
                "status": "crawling"
            },
            "videos": []
        }

        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(init_data, f, ensure_ascii=False, indent=2)
            print(f"ğŸ“ åˆå§‹åŒ–ä¿å­˜æ–‡ä»¶ï¼š{filepath}")
            return filepath
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–æ–‡ä»¶å¤±è´¥ï¼š{e}")
            return ""

    def append_videos_to_file(self, filepath: str, new_videos: List[Dict]) -> bool:
        """
        å¢é‡æ·»åŠ è§†é¢‘åˆ°æ–‡ä»¶

        Args:
            filepath: æ–‡ä»¶è·¯å¾„
            new_videos: æ–°è·å–çš„è§†é¢‘åˆ—è¡¨

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        if not new_videos:
            return True

        try:
            # è¯»å–ç°æœ‰æ•°æ®
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # è¿½åŠ æ–°è§†é¢‘
            data['videos'].extend(new_videos)
            data['user_info']['total_videos'] = len(data['videos'])
            data['user_info']['last_update'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

            # å†™å›æ–‡ä»¶
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            print(f"âœ… å·²è¿½åŠ  {len(new_videos)} ä¸ªè§†é¢‘ï¼Œæ€»è®¡ {data['user_info']['total_videos']} ä¸ª")
            return True

        except Exception as e:
            print(f"âŒ è¿½åŠ è§†é¢‘å¤±è´¥ï¼š{e}")
            return False

    def finalize_save_file(self, filepath: str) -> str:
        """
        å®Œæˆæ–‡ä»¶ä¿å­˜

        Args:
            filepath: æ–‡ä»¶è·¯å¾„

        Returns:
            æœ€ç»ˆæ–‡ä»¶è·¯å¾„
        """
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # æ›´æ–°æœ€ç»ˆçŠ¶æ€
            data['user_info']['status'] = 'completed'
            data['user_info']['end_time'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

            # é‡å‘½åæ–‡ä»¶ï¼ŒåŠ ä¸Šæœ€ç»ˆæ ‡è®°
            dir_path = os.path.dirname(filepath)
            base_name = os.path.basename(filepath)
            final_name = base_name.replace('.json', '_final.json')
            final_path = os.path.join(dir_path, final_name)

            with open(final_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            os.remove(filepath)

            print(f"\nğŸ‰ æœ€ç»ˆæ–‡ä»¶å·²ä¿å­˜ï¼š{final_path}")
            print(f"ğŸ“Š æ€»è®¡çˆ¬å– {data['user_info']['total_videos']} ä¸ªè§†é¢‘")

            return final_path

        except Exception as e:
            print(f"âŒ å®Œæˆä¿å­˜å¤±è´¥ï¼š{e}")
            return filepath

    def save_to_json(self, uid: int, videos: List[Dict]) -> str:
        """
        ä¿å­˜æ•°æ®åˆ°JSONæ–‡ä»¶ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰

        Args:
            uid: ç”¨æˆ·UID
            videos: è§†é¢‘åˆ—è¡¨

        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        data = {
            "user_info": {
                "uid": uid,
                "total_videos": len(videos),
                "crawl_time": current_time
            },
            "videos": videos
        }

        filename = f"videos_{uid}_{timestamp}.json"
        filepath = os.path.join(self.output_dir, filename)

        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            print(f"\næ•°æ®å·²ä¿å­˜åˆ°ï¼š{filepath}")
            return filepath

        except Exception as e:
            print(f"ä¿å­˜æ–‡ä»¶å¤±è´¥ï¼š{e}")
            return ""

    def run(self, uid: Optional[int] = None) -> bool:
        """
        è¿è¡Œçˆ¬è™«ä¸»ç¨‹åºï¼ˆä½¿ç”¨å¢é‡ä¿å­˜ï¼‰

        Args:
            uid: ç”¨æˆ·UIDï¼Œå¦‚æœä¸ºNoneåˆ™ä»å‘½ä»¤è¡Œè·å–

        Returns:
            æ˜¯å¦æˆåŠŸå®Œæˆ
        """
        # è·å–UID
        if uid is None:
            try:
                uid_input = input("è¯·è¾“å…¥Bç«™ç”¨æˆ·UIDï¼š").strip()
                if not uid_input:
                    print("é”™è¯¯ï¼šUIDä¸èƒ½ä¸ºç©º")
                    return False

                uid = int(uid_input)

            except ValueError:
                print("é”™è¯¯ï¼šè¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—UID")
                return False
            except KeyboardInterrupt:
                print("\n\nç¨‹åºå·²å–æ¶ˆ")
                return False

        print(f"\nå¼€å§‹çˆ¬å–ç”¨æˆ· {uid} çš„è§†é¢‘åˆ—è¡¨...")
        print("=" * 50)
        print("ğŸ’¾ ä½¿ç”¨å¢é‡ä¿å­˜æ¨¡å¼ï¼Œæ•°æ®ä¼šå®æ—¶ä¿å­˜åˆ°æ–‡ä»¶")

        # è·å–ç”¨æˆ·ä¿¡æ¯ï¼ˆæµ‹è¯•è¿æ¥ï¼‰
        test_data = self.get_user_info(uid)
        if not test_data:
            print("\nè·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥UIDæ˜¯å¦æ­£ç¡®")
            return False

        print(f"âœ… è¿æ¥æˆåŠŸï¼")
        print("\nğŸ“ æ³¨æ„ï¼šæ•°æ®ä¼šå®æ—¶ä¿å­˜ï¼Œå³ä½¿ç¨‹åºä¸­æ–­ä¹Ÿä¸ä¼šä¸¢å¤±å·²çˆ¬å–çš„æ•°æ®\n")

        # ä½¿ç”¨å¢é‡ä¿å­˜æ¨¡å¼çˆ¬å–è§†é¢‘
        total_videos = self.fetch_all_videos_with_incremental_save(uid)

        if total_videos == 0:
            print("\nâŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è§†é¢‘")
            return False

        print(f"\nâœ… çˆ¬å–å®Œæˆï¼å…±è·å–åˆ° {total_videos} ä¸ªè§†é¢‘")

        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“Š æœ€ç»ˆç»Ÿè®¡ï¼š")
        print(f"- æ€»è§†é¢‘æ•°ï¼š{total_videos}")
        print("- æ•°æ®å·²ä¿å­˜åˆ° output/ æ–‡ä»¶å¤¹")
        print("- æ–‡ä»¶åæ ¼å¼ï¼švideos_{uid}_æ—¶é—´æˆ³_final.json")

        print("\nğŸ’¡ æç¤ºï¼š")
        print("- å³ä½¿ç¨‹åºä¸­é€”å¤±è´¥ï¼Œå·²çˆ¬å–çš„æ•°æ®ä¹Ÿå·²ä¿å­˜")
        print("- å¯ä»¥æ£€æŸ¥ output/ æ–‡ä»¶å¤¹ä¸­çš„ä¸´æ—¶æ–‡ä»¶")

        return True


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 50)
    print("Bç«™è§†é¢‘çˆ¬è™«ç¨‹åºï¼ˆç®€åŒ–ç‰ˆï¼‰")
    print("=" * 50)
    print()

    # æ£€æŸ¥æ˜¯å¦æä¾›äº†å‘½ä»¤è¡Œå‚æ•°
    uid = None
    if len(sys.argv) > 1:
        try:
            uid = int(sys.argv[1])
        except ValueError:
            print("é”™è¯¯ï¼šå‘½ä»¤è¡Œå‚æ•°å¿…é¡»æ˜¯æ•°å­—UID")
            return

    # åˆ›å»ºçˆ¬è™«å®ä¾‹å¹¶è¿è¡Œ
    crawler = BilibiliSimpleCrawler()
    success = crawler.run(uid)

    if success:
        print("\nç¨‹åºæ‰§è¡Œå®Œæˆï¼")
    else:
        print("\nç¨‹åºæ‰§è¡Œå¤±è´¥ï¼")
        sys.exit(1)


if __name__ == "__main__":
    main()